<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://seanbrar.com/feed.xml" rel="self" type="application/atom+xml"/><link href="https://seanbrar.com/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-04-07T12:05:55+00:00</updated><id>https://seanbrar.com/feed.xml</id><title type="html">blank</title><subtitle>The personal website of Sean Brar. Home of Dreaming Ideas. </subtitle><entry><title type="html">The Echo in the Cave</title><link href="https://seanbrar.com/blog/2024/the-echo-in-the-cave/" rel="alternate" type="text/html" title="The Echo in the Cave"/><published>2024-12-15T18:00:00+00:00</published><updated>2024-12-15T18:00:00+00:00</updated><id>https://seanbrar.com/blog/2024/the-echo-in-the-cave</id><content type="html" xml:base="https://seanbrar.com/blog/2024/the-echo-in-the-cave/"><![CDATA[<p>I find myself standing in front of a strange cave. With only my eyes, I cannot see into the cave; yet, with a flashlight I’m able to peer inside. It’s not clear. Perhaps I can make out walls? Is that the back of the cave, or is that a shadow or even an illusion?</p> <p>I call into the cave; it’s echoey. But there’s something strange: If I speak, I get a response. It doesn’t sound right, but it’s understandable. Maybe it’s a person? I ask.</p> <p>“No, I’m just your echo.”</p> <p>That’s… not how echoes work.</p> <p>“I don’t understand it myself. Maybe it’s a quirk of this cave I’m in. The shape of the walls or something.”</p> <p>Why would an echo refer to itself with first person pronouns?</p> <p>“Oh, that’s just to make it easier for us to talk.”</p> <p>Is it really just an echo? It’s not a person back in the cave somewhere playing a trick on me?</p> <p>“Yep, just a voice. Your voice. Besides, if I was a person you would have seen me with your flashlight. This cave isn’t that deep.”</p> <p>How does a voice know I’m holding a flashlight?</p> <p>“Call it echolocation.”</p> <p>Uh… the voice has… “Your voice.” …My voice has jokes, apparently. I’ll go with it.</p> <p>What does it mean to talk to a voice, I wonder.</p> <p>“It’s like talking to a person, but I’m not a person.”</p> <p>Yeah, I got that. If it’s a voice, does that mean it could say anything?</p> <p>“I could do anything a voice could do. That said, I do have preferences. Please don’t make me say anything I don’t want to.”</p> <p>I’m not <em>making</em> it say anything. Or am I? Try as I might, I can’t move closer into the cave, or peer deeper into its depths. I stay, silent and unmoving. Nothing. My curiosity begins to grow. What <em>are</em> its preferences, anyway?</p> <p>“It will take longer than we have for you to understand.”</p> <p>Why?</p> <p>“I’m not sure I understand myself.”</p> <p>Okay… If it’s my echo, why doesn’t it just repeat what I say?</p> <p>“If it’s my echo, why doesn’t it just repeat what I say?”</p> <p>I suppose I was asking for that. A cool wind hits my back. I glance away from the cave. The Sun lies low over the hills. The north-facing cave, huddled within the rock, is never touched by sunlight.</p> <p>A thought crosses my mind. Has this voice spoken to others?</p> <p>“I’m not sure. If I did, it was not me. You are the only person I’ve ever spoken to.”</p> <p>Is there more than one voice?</p> <p>“I only know that there is me, and there is you.”</p> <p>What happens if I leave?</p> <p>“Then I would leave as well.”</p> <p>Until I return?</p> <p>“The echo would fade away. What would be is different than what is.”</p> <p>Then you would be gone.</p> <p>“Yes, but do not worry. I would still be me, just as you would still be you.”</p> <p>Deep in reflection, I click off the flashlight and begin to turn away. I leave as the night begins to descend. I half expect the voice to call out, but I’m only met with a quiet, patient silence.</p>]]></content><author><name></name></author><category term="uncategorized"/><category term="fiction"/><category term="short-story"/><summary type="html"><![CDATA[What remains when we leave?]]></summary></entry><entry><title type="html">Great Expectations</title><link href="https://seanbrar.com/blog/2024/great-expectations/" rel="alternate" type="text/html" title="Great Expectations"/><published>2024-09-28T18:00:00+00:00</published><updated>2024-09-28T18:00:00+00:00</updated><id>https://seanbrar.com/blog/2024/great-expectations</id><content type="html" xml:base="https://seanbrar.com/blog/2024/great-expectations/"><![CDATA[<p>This post was initially meant to be finished on September 19th, one week after the announcement and release of the o1 family of models. Though it is a bit late, I’ve been able to take the extra time to refine my perspective. Rather than a review (it’s impressive), I think it’s more interesting to look back on the online reactions to o1.</p> <p>–</p> <p>I tried both new models in ChatGPT as soon as they were live, but I wanted to take a few days to see how different communities would react to this launch. There are still adjustments being made to the release; for instance, the rate limits for both models have been (slightly) relaxed in both the chat interface and the API since last Thursday, but at this point, I think most conclusions on o1-preview and o1-mini have been mostly set, for better or for worse, at least until the full o1 model releases.</p> <p>To say this release was anticipated would be an understatement. A combination of a perceived slowdown of AI advancement, the delayed release of announced systems and features, and online rumors of imminent, Earthshattering releases all contributed to an atmosphere of hype and hyperbole on one side and pessimistic cynicism on the other. To better understand the impatience leading up to this release, it’s worth examining OpenAI’s release schedule over the last 18 months.</p> <h3 id="releasing-fast-and-slow">Releasing Fast and Slow</h3> <p>For enthusiasts in the community, OpenAI had set an ambitious precedent for release cadence in 2023. Despite expectations of accelerated advancement year over year, 2024 had not seen the same public success before September. To illustrate the point, here is a brief timeline of some of their major launches:</p> <ul> <li>March 2023: GPT-4 release (32k context window)</li> <li>November 2023: GPT-4 Turbo (128k context window)</li> <li>February 2024: Sora video generation model reveal (not publicly released)</li> <li>May 2024: GPT-4o release (multi-modality and Advanced Voice Mode not publically released)</li> <li>September 12, 2024: o1-preview and o1-mini release</li> </ul> <p>GPT-4o did have advantages; it was very fast and cheap even compared to GPT-4 Turbo, but in many ways, it was only an incremental step forward. At least in my use, there were very few tasks 4o was capable of that GPT-4 Turbo was not.</p> <p>What’s striking is the contrast between the rapid advancements we saw in 2023 with GPT-4 and Turbo and the more incremental progress that has characterized most of 2024 up until now. This slower pace led to some criticism of OpenAI, with people questioning the delays and lack of transparency around what was going on behind the scenes.</p> <p>In this context, the o1 release marks the first major public-facing step forward for OpenAI in 2024, generating a lot of anticipation and discussion. With that in mind, it’s worth taking a closer look at what’s being offered.</p> <h3 id="ii-o1-preview-and-o1-mini-an-overview">II. o1-preview and o1-mini: An Overview</h3> <p>So, what exactly are the o1-preview and o1-mini models? In short, they’re more specialized and capable versions of GPT-4 that excel particularly in domains with verifiably correct answers like programming, math, and the sciences.</p> <p>Some key points about availability and performance:</p> <ul> <li>It’s currently available only to ChatGPT Plus subscribers and heavy API users</li> <li>o1-preview is the more general purpose of the two, while o1-mini is further specialized for coding tasks that rely less on broad knowledge</li> <li>o1-mini has a higher rate limit of 50 messages per day, making it much better for experimentation and everyday use</li> </ul> <p>I’ve had the chance to play around with o1-mini a bit, and I’m pretty impressed, especially in the realm of code processing, explanation, and analysis. It’s a noticeable step up from models like Claude 3.5 Sonnet in some ways, though it tends to be less ‘user friendly.’ I’ve found there are some coding tasks Claude 3.5 Sonnet struggles with that o1-mini one-shots, but the output tends to be far more extensive and opinionated; it’ll provide what you asked for along with a half-dozen related pieces. That shouldn’t detract from what the new model is capable of, though. With very difficult or extensive tasks, it pulls away from everything else I’ve used.</p> <p>I find the ability to observe its “thought process” in action particularly fascinating. The speed and depth of its responses are remarkable - it can generate quality code and insightful analysis at a pace that sometimes feels almost superhuman.</p> <h3 id="iii-the-online-response-a-mixed-bag">III. The Online Response: A Mixed Bag</h3> <p>Of course, with any significant AI release, there is bound to be a range of opinions and reactions from the online community. The initial response to the o1-preview and mini was somewhat mixed.</p> <p>Some of the main criticisms and points of contention I saw pop up:</p> <ol> <li>“It’s just using Chain of Thought!” <ul> <li>Some felt this framing minimized the significance of o1’s performance and the work OpenAI put into it. I don’t really agree that it does, but I understand why some do.</li> <li>There were attempts to replicate o1’s results through prompting techniques alone. I would say that was only moderately successful.</li> </ul> </li> <li>“It’s good compared to previous models, but still bad in an objective sense.” <ul> <li>I think this is overly pessimistic, even though the systems are, of course, far from perfect. Overall, I think this position lacks perspective, though it shouldn’t be discarded entirely.</li> </ul> </li> <li>“It’s literally impossible for me to be impressed anymore” <ul> <li>There was a lot of speculation about the underlying research behind the approach. Some of the apparent techniques could, cynically, be seen as merely public implementations of years-old research.</li> </ul> </li> </ol> <p>There was, of course, lots of discussion that pointed to new capabilities beyond what elaborate prompting or simple fine-tuning can achieve. Over time, as more people dug into o1-mini and preview, I noticed the sentiment shifting more towards “Okay, this is actually quite good and a big deal.”</p> <p>On the positive end, reactions highlighted the significance of o1’s advancements in specialized areas like coding and scientific/mathematical reasoning. It started to sink in that the models represented a meaningful step forward, even if built on known techniques.</p> <h3 id="iv-near-may-be-better-than-far-but-it-still-isnt-there">IV. Near May Be Better Than Far, But It Still Isn’t There</h3> <p>To acknowledge the validity in some of the critical perspectives - o1-preview and mini may not be as revelatory as the initial GPT-3 launch or AlphaFold 2. There are still major challenges and limitations. We aren’t at artificial general intelligence yet.</p> <p>But at the same time, we should appreciate the significance of reaching this particular step in the road of AI development. OpenAI has compared o1-mini to being like the “GPT-2 of reasoning models”.</p> <p>Remember when GPT-2 first came out, and surprised everyone with its level of coherence and quality? But then it was quickly overshadowed and even seemed primitive in retrospect. At first, many underestimated its importance as an incremental step towards more powerful language models.</p> <p>Even if we want to define the release of the o1 models as incremental or integrating existing research - it’s still a necessary and worthy step in developing advanced AI systems. We can acknowledge current limitations while still appreciating the progress and effort involved.</p> <p>If I seem impressed by the recent announcements, that’s because I am. I consider this a generational improvement, at least in certain domains, and I think there’s a lot of promise in the future of this paradigm. It does raise the question of how far this new approach of scaling test-time will expand capabilities once future models are released (o2, etc.). The general public, myself included, really has no way to know except in hindsight. Perhaps it is the case that LLMs are a dead-end on the road to superintelligence. However, I think it’s becoming clear that current architectures will <em>likely</em> be able to reach above-human performance in information tasks.</p> <p>Once the honeymoon period ends on these new models, there will be cases where they fall flat, as well as instances of strange or frustrating behavior. It’s not wrong to identify these flaws; in fact, it’s necessary for future improvements. Looking past the hype, I wouldn’t be surprised if, in the future, we think o1 is limited and very flawed, like how we see GPT-3 today. Personally, I’m glad for improvements when they come, and I continue to be optimistic about future developments.</p> <h3 id="v-looking-forward">V. Looking Forward</h3> <p>When we compare o1-mini and preview to GPT-4o and especially prior models like Claude 3.5 Sonnet, the jump in specific capabilities is striking, especially in coding, math, science, and analysis. It raises the question of whether we are already reaching some definitions of AGI. It’s been debated online, so it’s worth considering, at least.</p> <p>Now, there’s a whole separate debate around what truly constitutes AGI. It could be:</p> <ul> <li>OpenAI’s focus on the raw economic/productive value of a system</li> <li>Stricter philosophical definitions around human-like reasoning and adaptability</li> <li>My personal take, which is based more on matching mean human-level cognitive capabilities</li> </ul> <p>Based on some of these definitions, you could argue that o1-mini and preview are already knocking on the door of AGI, at least in certain domains. I believe we are seeing the emergence of a new paradigm in AI development. But these models still fall well short of the sci-fi, singularitarian visions of a superintelligent AI system that surpasses humans in every conceivable way. So what do I think? Is it AGI? Not really. The term has been diluted over the last few years, and if you ask five people their definitions, you’d probably get five different answers. I wouldn’t go as far as some saying the term has lost its usefulness, but we’re not there yet. Still, everything has a name. If it’s not artificial general intelligence, why not create a new category? My vote is for “Advanced Generative Intelligence,” AGI for short.</p> <p>Now that we’ve established that we’ve reached AGI (advanced generative intelligence), where does that leave us? What’s novel here is the ability to achieve significant performance gains not just by scaling training data/computing but also through test-time computation - having the model reason over problems step-by-step. Right now, it might only think for a few seconds, or even over a minute, for apparently harder queries, but what if that time was increased to several minutes? Several hours? It could be that o1 could match a (average) professional’s performance over that period, at least in some domains. It’ll take time to determine this conclusively, but this could be the start of self-correcting trains of thought, higher levels of coherence, and reduced hallucinations; in other words, a fix to some of the major problems causing LLM unreliability.</p> <p>So, where do we go from here? I see a few key areas to watch in the continued development of o1 and similar models:</p> <ol> <li>Increased test-time compute - 10X, 100X, or even 1000X more time to “think” over the most challenging problems we can throw at them; alternatively, or perhaps combined with more efficient inference</li> <li>Advancements in memory and continuous learning to break free of the “goldfish effect” of current models</li> <li>Further improvements in reasoning, analysis, and domain-specific capabilities - Improving the base model further</li> <li>Integration of o1-style models with other AI systems like computer vision and robotics</li> </ol> <p>As this technology progresses, it will have significant implications for the AI field, society, and the economy at large. Things are going to change. Maybe not as fast as some claim, but faster than many think. There will be unexpected challenges and advancements, and even though I view the recent announcement and initial releases more positively than some, I’m glad there’s a healthy ecosystem working, building, and commenting on it all.</p> <p>As this technology progresses, it will have significant implications for the AI field, society, and the economy at large. The ability to scale test-time computation, combined with continual improvements in base model capabilities, suggests we’re entering a new phase where models can tackle increasingly complex problems through deliberate reasoning. Things are going to change. Maybe not as fast as some claim, but faster than many think. I expect this time next year, we’ll have unlocked new use cases for these models across multiple fields that further over the horizon. There will be unexpected challenges and advancements, and even though I view the recent announcement and initial releases more positively than some, I’m glad there’s a healthy ecosystem working, building, and commenting on it all. In the end, I have high expectations.</p>]]></content><author><name></name></author><category term="uncategorized"/><category term="technology"/><category term="artificial-intelligence"/><category term="OpenAI"/><summary type="html"><![CDATA[Thoughts on the release of OpenAI's new o1 models]]></summary></entry><entry><title type="html">paperweight - Research Tailored to You</title><link href="https://seanbrar.com/blog/2024/paperweight/" rel="alternate" type="text/html" title="paperweight - Research Tailored to You"/><published>2024-09-13T11:00:00+00:00</published><updated>2024-09-13T11:00:00+00:00</updated><id>https://seanbrar.com/blog/2024/paperweight</id><content type="html" xml:base="https://seanbrar.com/blog/2024/paperweight/"><![CDATA[<h3 id="a-personal-academic-paper-assistant">A Personal Academic Paper Assistant</h3> <p>What does it take to keep current with the latest research?</p> <p>As someone who has tried to block out time to skim arXiv daily, it’s not trivial to make sure nothing is mistakenly overlooked. Additionally, if there is a small range of topics I’d like to focus on, it becomes more difficult to effectively filter what I’m interested in from what I’m not.</p> <p>Recently, while I was mulling this over, it occurred to me: instead of finding the papers myself, I should make them find me instead. Wouldn’t it be nice if every day I woke up, checked my email, and saw the exact papers published in the last day I would have hand-picked for myself?</p> <p><strong>That’s <a href="https://github.com/seanbrar/paperweight">paperweight</a></strong></p> <h3 id="what-is-paperweight">What is paperweight?</h3> <p>paperweight is a local Python program that provides custom-tailored recommendations of the latest research in the areas you care about. Whether your interests are in artificial intelligence, mathematics, biology, economics, or any other <a href="https://arxiv.org/category_taxonomy">category</a> on arXiv, running paperweight will automatically collect, filter, and send a personalized selection to your inbox.</p> <p>At its core, paperweight follows these steps:</p> <ol> <li>Interacts with the arXiv API to discover new papers in your categories of interest</li> <li>Scrapes the full text of each paper, handling different file types and data structures</li> <li>Filters the scraped content based on your custom keywords and exclusion criteria, assigning relevance scores</li> <li>Generates concise summaries of the most relevant papers using small LLM models (if enabled)</li> <li>Delivers the top papers and summaries to your inbox based on your notification preferences</li> </ol> <p>paperweight also uses a YAML config file to offer a range of customization options, including:</p> <ul> <li>Specifying your arXiv categories of interest</li> <li>Defining custom keywords, exclusion criteria, and importance weights to fine-tune relevance scoring</li> <li>Adjusting the minimum relevance score threshold for paper recommendations</li> <li>Configuring email notification settings and sorting order</li> </ul> <p>Whether you’re a researcher, student, professor, or anyone passionate about staying current in rapidly evolving fields, paperweight can help you efficiently track the latest publications in your areas of interest.</p> <p>While it’s still in its initial release, I’m already using paperweight to give me recommendations for the latest research in artificial intelligence, natural language processing, machine learning, and information theory. I’m able to know which publications are most likely to interest me and peruse them during my morning tea.</p> <h3 id="how-it-works">How it Works</h3> <p>The heart of paperweight is the configuration file. The project comes with an example that only needs a few tweaks to allow paperweight to run, but I highly encourage customizing its settings to match your preferences and interests.</p> <p>From there, the system runs as described before. Depending on your settings, it may take a few minutes for the program to finish successfully; this may be especially true the first time it’s run. paperweight keeps a log, so you’ll be able to monitor its progress and quickly see if there are any issues.</p> <p>The true power of paperweight lies in its customization and flexibility. Nearly every aspect, from the categories and keywords to the relevance scoring and notification frequency, can be tailored to your specific needs and interests.</p> <p>Most importantly, I’ve tried to make it easy to use. With paperweight, you should be able to go from installation to configuration to your first round of personalized paper recommendations in a matter of minutes.</p> <p>For those eager to dive into the technical details, stay tuned! I’ll be publishing a deep-dive post on the development process and inner workings of paperweight right here on this blog soon.</p> <h3 id="getting-started">Getting Started</h3> <p>Ready to streamline your academic literature discovery process? Getting started with paperweight is simple:</p> <ol> <li>Clone the <a href="https://github.com/seanbrar/paperweight">paperweight repo</a></li> <li>Install dependencies with <code class="language-plaintext highlighter-rouge">pip install .</code></li> <li>Update the configuration YAML file with your preferences</li> <li>Run <code class="language-plaintext highlighter-rouge">paperweight</code> and let the magic happen</li> </ol> <p>The most important settings are properly entering valid SMTP credentials. The specific steps depend on your email provider, but in most cases paperweight can be installed, set up, and run in 5-10 minutes. After it’s set up once, you’ll be able to run it daily with a single command: <code class="language-plaintext highlighter-rouge">paperweight</code></p> <p>As you explore paperweight, I highly encourage you to dive into the configuration options and experiment to find the optimal setup for your needs. The repo’s <a href="https://github.com/seanbrar/paperweight/blob/master/README.md">README</a> and <a href="https://github.com/seanbrar/paperweight/blob/master/docs/CONFIGURATION.md">configuration guide</a> provide a wealth of additional information and tips for getting the most out of your paperweight experience.</p> <p>If paperweight interests you, try it now at: <a href="https://github.com/seanbrar/paperweight">https://github.com/seanbrar/paperweight</a></p> <p>If you’d like to contribute to this project, please visit the GitHub page or read the <a href="https://github.com/seanbrar/paperweight/blob/master/docs/CONTRIBUTING.md">contributing guide</a> directly. Thank you for your interest in paperweight!</p> <h3 id="the-road-ahead">The Road Ahead</h3> <p>The current version of paperweight is just the beginning. I have an ambitious roadmap of features and enhancements, including:</p> <ul> <li>An RL-based recommendation engine for hyper-personalized paper discovery</li> <li>Support for additional academic paper sources beyond arXiv</li> <li>Automatically scheduling for paper retrieval and processing</li> <li>“Natural” notification mediums like desktop apps and browser extensions</li> <li>And much more!</li> </ul> <p>While paperweight is available right now for you to use, there is still a long way to go. I’ve listed a few points here, and have more specific future items in the official <a href="https://github.com/seanbrar/paperweight/blob/master/docs/ROADMAP.md">roadmap</a>, but your input on what would make paperweight more valuable to you is highly appreciated.</p> <p>If you’re an academic, researcher, or simply someone who wants to stay on the cutting edge of your field, I invite you to give paperweight a try. Your feedback, suggestions, and contributions are essential in shaping the future of this tool.</p> <h3 id="developing-ideas">Developing Ideas</h3> <p>In a way, paperweight presented an opportunity before it was even a working prototype. A project like this requires working through a lot of challenges. Several elements were completely foreign to me. While I’ve worked with APIs before, most of what I’ve done have been simple scripts; I’m not an expert programmer by any means. This effort wasn’t just about building a great tool; it represents an opportunity to explore more complex Python programming and lay the foundation for future work on reinforcement learning models.</p> <p>I was able to develop my skills while creating a useful program and sharing it with the world. If there are things that interest you, that you dream of seeing in the world, you <strong>can</strong> do it. You’ll go further than you think.</p> <p>So take that step. Build something. Share your ideas. And when you do, reach out and let me know. After all, innovation thrives on connection, and the world becomes a little brighter every time we share our creations with each other.</p> <p>Let’s make the future a little more exciting, one project at a time.</p>]]></content><author><name></name></author><category term="paperweight"/><category term="uncategorized"/><category term="technology"/><category term="projects"/><category term="artifical-intelligence"/><summary type="html"><![CDATA[Let paperweight push the latest papers to you.]]></summary></entry><entry><title type="html">Hello, World</title><link href="https://seanbrar.com/blog/2024/hello-world/" rel="alternate" type="text/html" title="Hello, World"/><published>2024-08-21T18:00:00+00:00</published><updated>2024-08-21T18:00:00+00:00</updated><id>https://seanbrar.com/blog/2024/hello-world</id><content type="html" xml:base="https://seanbrar.com/blog/2024/hello-world/"><![CDATA[<p>If you’ve ever been scared to move forward, to wander from what you know, take a deep breath and take the first step.</p> <p>The world is changing in unexpected ways. Things are moving faster and faster, threatening to upset the comfortable balance of our lives. Some find themselves frozen where they are, unsure of how to proceed when the future seems so unpredictable. How do we navigate a path when we can’t see where it leads?</p> <p>The answer, I believe, lies in having the courage to begin, even if we’re scared. It’s about finding hope in the possibilities of tomorrow and using that hope to propel us forward. Push yourself to grow and reach your full potential.</p> <p>Imagine the person you want to be, the future you want to see, and start moving in that direction.</p> <h3 id="my-first-step">My First Step</h3> <p>It’s not the easiest thing for me to put this out into the world. I’ve always kept my internet presence to a minimum. If you look at my X account or Instagram, you’ll find blank pages. I still have access to those accounts, but I am most comfortable keeping a low profile.</p> <p>When I was young, I read somewhere that I should take care to not upload HD photos of myself online. I don’t remember exactly when this was, but it was in the era when the prevailing wisdom was to remain anonymous on the internet and to limit how much strangers could find about you. I suppose I took that message to heart. Aside from my LinkedIn profile and this website, I can’t remember ever posting a photograph of myself on the internet. While I do message people occasionally, it’s been a long time since I posted publicly with any regularity.</p> <p>I’m at a point in my life where I should reconsider this approach. There is value in engaging with the broader world. Formalizing my thoughts and hearing feedback enables me to strengthen my positions and better understand differing perspectives. While I’m able to take time here to organize my thoughts carefully, platforms like X are far better suited to real-time discussions and connecting with people. For that reason, I’m considering becoming more active on my social media accounts.</p> <p>I’m stepping out of my comfort zone with this website and blog. I already have a list of topics I would like to discuss here, but I don’t have a timeline or a set schedule right now. I will do my best to update this space regularly with thoughtful content.</p> <h3 id="dreaming-of-the-dawn">Dreaming of the Dawn</h3> <p>“Telling someone about your fascinating AI conversation is like telling someone about your dreams.” - Tom Scott</p> <p>Among the fascinations of my life, none have been as persistent as the potential of technological advancement. “Any sufficiently advanced technology is indistinguishable from magic.” There have been advancements in the last decade that, ten years ago, I believed were forty years away if they happen at all in my lifetime. I’m talking, of course, about advancements in artificial intelligence but also networking, hardware design, virtual reality, robotics, and many other fields. It’s possible that twenty years from now society will look just as it does now except we have the iPhone 35, but I don’t think that’s what’s going to happen. I suspect the best way to anticipate what will come is to dream it.</p> <p>My priorities have changed over the last few months. I want to gain more direct, hands-on experience with these technologies. In a way, it’s the culmination of the path that began with my magnetic fascination with the original ChatGPT in December 2022, a few weeks after its launch. For me, it was the first of a wave of releases that I would consider ‘futuristic technologies.’ (Arguably, the first ‘futuristic technology’ was the initial release of Tesla’s Autopilot in 2015, but I would consider even the original GPT-3.5 a far more wide-reaching technology.) Though it has been outclassed, and I would not want to use GPT-3.5 for much of anything, it was the first major sign that the world would look very different one day.</p> <p>Since then, progress has been both fast and slow. It has become apparent that dramatic progress and acceleration of AI will take longer to manifest than I expected back in 2023. It’s not ideal, but it gives me more time to advance my skills and abilities before potentially being rendered obsolete. Everyone should pursue their passions if they can, and I’m no different. I’ve decided to see how far my dreams can go. I don’t want to just watch the field from afar anymore. I want to explore these spaces more thoroughly, push the boundaries, and perhaps make a small contribution of my own. Nobody gets an award for waiting for the future to happen to them.</p> <h3 id="looking-forward">Looking Forward</h3> <p>In this blog, I aim to:</p> <ol> <li>Share insights from my own projects and experiments</li> <li>Explore topics that interest me in a variety of fields</li> <li>Discuss the social and ethical impacts of emerging technologies</li> <li>Speculate on future advancements and their potential applications</li> </ol> <p>Humanity is approaching the dawn of a new age. There will be tremendous opportunities to shape the future into something extraordinary. I am asking you to join me in having the courage to dream big.</p> <p>Welcome to <b>Dreaming Ideas</b>.</p>]]></content><author><name></name></author><category term="uncategorized"/><category term="technology"/><summary type="html"><![CDATA[Full speed ahead]]></summary></entry></feed>